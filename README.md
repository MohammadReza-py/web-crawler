# ğŸ•·ï¸ Async Web Crawler & Keyword Finder

A blazing-fast **web crawler** written in **Python** ğŸš€  
This project is built with a special focus on **Asynchronous Programming** using `asyncio` and `aiohttp`.  
It crawls links, checks their availability, and searches for a keyword inside webpages â€” **all concurrently** for maximum performance âš¡.  

---

## ğŸ”¥ Programming Style
This project uses **Asynchronous Programming (async/await)** in Python:  
- Built with `asyncio` for managing event loops and concurrency  
- Uses `aiohttp` for **non-blocking HTTP requests**  
- Combines async tasks with synchronous code (`requests` + `BeautifulSoup`) for efficient parsing  
- Faster, scalable, and more resource-friendly compared to traditional synchronous crawlers  

âœ… **Core Skill Demonstrated**: *Async/await concurrency with Python* 

---

## âœ¨ Features
- âš¡ **Asynchronous Crawling** (powered by `asyncio` & `aiohttp`)
- ğŸ”— **Link Extraction** from webpages
- âœ… **Availability Check** for each link (status < 400)
- ğŸ” **Keyword Search** inside webpages (using BeautifulSoup)
- ğŸ—‘ **Duplicate Removal** to keep results clean
- ğŸ–¥ **Interactive CLI**: input website & keyword directly

---

## ğŸ“¦ Installation
Clone the repo and install dependencies:

```bash
git clone https://github.com/your-username/web-crawler.git
cd web-crawler
pip install -r requirements.txt
```

ğŸš€ Usage

Run the script:
```bash
python crawler.py
```

Enter:

ğŸŒ Website URL

ğŸ”‘ Keyword you want to find

Output:

Total links found

Cleaned & valid links

Links containing your keyword

ğŸ›  Requirements

Python 3.8+

Libraries:
- requests
- beautifulsoup4
- aiohttp

You can install them with:
```bash
pip install requests beautifulsoup4 aiohttp
```

ğŸ“œ License

MIT License Â© 2025 MohammadReza Bidar
